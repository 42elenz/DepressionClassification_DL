{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import urllib\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import mne\n",
    "import helper as h\n",
    "import functionss as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_edf('/home/ubuntu/hyperparameter_tuning/data/H_EC/H S7 EC.edf', preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.drop_channels(\n",
    "                    [\n",
    "                        \"EEG A2-A1\",\n",
    "                        \"EEG 23A-23R\",\n",
    "                        \"EEG 24A-24R\",\n",
    "                        \"EEG T6-LE\",\n",
    "                        \"EEG Cz-LE\",\n",
    "                        \"EEG Pz-LE\",\n",
    "                    ],\n",
    "                    on_missing=\"ignore\",\n",
    "                )\n",
    "raw = raw.rename_channels(\n",
    "                    {\n",
    "                        \"EEG Fp1-LE\": \"Fp1\",\n",
    "                        \"EEG F3-LE\": \"F3\",\n",
    "                        \"EEG C3-LE\": \"C3\",\n",
    "                        \"EEG P3-LE\": \"P3\",\n",
    "                        \"EEG O1-LE\": \"O1\",\n",
    "                        \"EEG F7-LE\": \"F7\",\n",
    "                        \"EEG Fz-LE\": \"Fz\",\n",
    "                        \"EEG Fp2-LE\": \"Fp2\",\n",
    "                        \"EEG F4-LE\": \"F4\",\n",
    "                        \"EEG C4-LE\": \"C4\",\n",
    "                        \"EEG P4-LE\": \"P4\",\n",
    "                        \"EEG O2-LE\": \"O2\",\n",
    "                        \"EEG F8-LE\": \"F8\",\n",
    "                        \"EEG T3-LE\" : \"T3\",\n",
    "                        \"EEG T5-LE\" : \"T5\",\n",
    "                        \"EEG T4-LE\" : \"T4\",\n",
    "                    }\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_names = raw.ch_names\n",
    "len(ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = raw.get_data()\n",
    "array.shape\n",
    "array = array[:, 0:1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_eeg = h.transform_array(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch_eeg.shape[0]\n",
    "y = torch_eeg.shape[1]\n",
    "print(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_eeg = h.transform_array(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_reshaped, min_val, max_val = torch_eeg.reshape(1,x*y)\n",
    "torch_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_names=['Fp1', 'F3', 'C3', 'P3', 'O1', 'F7', 'Fz', 'Fp2', 'F4', 'C4', 'P4', 'O2', 'F8', 'T6', 'Cz', 'Pz']\n",
    "raw_array=h.reverse_transform_array(torch_reshaped, min_val, max_val,changed_shape=True)\n",
    "raw_re=f.array_to_edf(raw_array,ch_names,'eeg','test.edf')\n",
    "raw_re.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel:\n",
    "\tdef __init__(self, start_shedule=0.0001, end_schedule=0.02, timesteps=300):\n",
    "\t\tself.start_schedule = start_shedule\n",
    "\t\tself.end_schedule = end_schedule\n",
    "\t\tself.timesteps = timesteps\n",
    "\t\t\n",
    "\t\tself.betas = torch.linspace(self.start_schedule, self.end_schedule, self.timesteps)\n",
    "\t\tself.alphas = 1-self.betas\n",
    "\t\tself.alpha_cumprod = torch.cumprod(self.alphas,axis=0)\n",
    "\n",
    "\tdef forward(self, x0, t, device, min_val, max_val):\n",
    "\t\t#noise= (min_val - max_val) * torch.rand_like(x0) + max_val * -1\n",
    "\t\tnoise = torch.randn_like(x0)/2 #funktion mit std und min, max von meinen Daten\n",
    "\t\tsqrt_alphas_cumprod_t = self.get_index_from_list(self.alpha_cumprod.sqrt(), t, x0.shape)\n",
    "\t\tsqrt_one_minus_alphas_cumprod_t = self.get_index_from_list(torch.sqrt(1. - self.alpha_cumprod), t, x0.shape)\n",
    "\t\tmean = sqrt_alphas_cumprod_t.to(device) * x0.to(device)\n",
    "\t\tvariance = sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device)\n",
    "\t\treturn mean + variance, noise.to(device)\n",
    "\t\n",
    "\tdef backward(self, x, t, model, **kwargs):\n",
    "\t\t\"\"\"\n",
    "\t\tCalls the model to predict the noise in the image and returns \n",
    "\t\tthe denoised image. \n",
    "\t\tApplies noise to this image, if we are not in the last step yet.\n",
    "\t\t\"\"\"\n",
    "\t\tbetas_t = self.get_index_from_list(self.betas, t, x.shape)\n",
    "\t\tsqrt_one_minus_alphas_cumprod_t = self.get_index_from_list(torch.sqrt(1. - self.alpha_cumprod), t, x.shape)\n",
    "\t\tsqrt_recip_alphas_t = self.get_index_from_list(torch.sqrt(1.0 / self.alphas), t, x.shape)\n",
    "\t\tmean = sqrt_recip_alphas_t * (x - betas_t * model(x, t, **kwargs) / sqrt_one_minus_alphas_cumprod_t)\n",
    "\t\tposterior_variance_t = betas_t\n",
    "\n",
    "\t\tif t == 0:\n",
    "\t\t\treturn mean\n",
    "\t\telse:\n",
    "\t\t\tnoise = torch.randn_like(x)/2\n",
    "\t\t\tvariance = torch.sqrt(posterior_variance_t) * noise \n",
    "\t\t\treturn mean + variance\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef get_index_from_list(values, t, x_shape):\n",
    "\t\tbatch_size = x_shape[0]\n",
    "\t\tresult = values.gather(-1,t.cpu())\n",
    "\n",
    "\t\treturn result.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_model = DiffusionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_OF_IMAGES = 5\n",
    "batch_images = torch.stack([torch_reshaped] * NO_OF_IMAGES)\n",
    "t = torch.linspace(0, diffusion_model.timesteps - 1, NO_OF_IMAGES).long()\n",
    "noisy_edfs, _ = diffusion_model.forward(batch_images, t, 'cpu', min_val = min_val, max_val = max_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, edf in enumerate(noisy_edfs):\n",
    "\traw_array=h.reverse_transform_array(edf, min_val, max_val,changed_shape=True)\n",
    "\traw=f.array_to_edf(raw_array,ch_names,'eeg','test.edf')\n",
    "\traw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_model = h.DiffusionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_noise_distribution(noise, predicted_noise):\n",
    "    plt.hist(noise.cpu().numpy().flatten(), density = True, alpha = 0.8, label = \"ground truth noise\")\n",
    "    plt.hist(predicted_noise.cpu().numpy().flatten(), density = True, alpha = 0.8, label = \"predicted noise\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out, time_embedding_dims, downsample=True):\n",
    "        super().__init__()\n",
    "        self.time_embedding_dims = time_embedding_dims\n",
    "        self.time_embedding = SinusoidalPositionEmbeddings(time_embedding_dims)\n",
    "\n",
    "        if downsample:\n",
    "            self.conv1 = nn.Conv1d(channels_in, channels_out, kernel_size=3, padding=1)\n",
    "            self.final = nn.Conv1d(channels_out, channels_out, kernel_size=4, stride=2, padding=1)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv1d(2*channels_in, channels_out, kernel_size=3, padding=1)\n",
    "            self.final = nn.ConvTranspose1d(channels_out, channels_out, kernel_size=4, stride=2, padding=1)\n",
    "        \n",
    "        #Set rest of the layers\n",
    "        self.bnorm1 = nn.BatchNorm1d(channels_out)\n",
    "        self.bnorm2 = nn.BatchNorm1d(channels_out)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(channels_out, channels_out, kernel_size=3, padding=1)\n",
    "        self.time_mlp = nn.Linear(time_embedding_dims, channels_out)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, t, **kwargs):\n",
    "        o=self.conv1(x)\n",
    "        o = self.relu(o)\n",
    "        o = self.bnorm1(o)\n",
    "        t = self.time_embedding(t)\n",
    "        t = self.time_mlp(t)\n",
    "        o_time = self.relu(t)\n",
    "        o_time = o_time[(..., ) + (None, ) * 1]\n",
    "        o = o + o_time\n",
    "        o = self.conv2(o)\n",
    "        o = self.relu(o)\n",
    "        o = self.bnorm2(o)\n",
    "        o = self.final(o)\n",
    "        return o\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, time_embedding_dims=128):\n",
    "        super().__init__()\n",
    "        time_embedding_dims = time_embedding_dims\n",
    "        down_channels = [64, 128, 256]\n",
    "        up_channels = [256, 128, 64]\n",
    "        out_channels = 1\n",
    "        in_channels = 1\n",
    "\n",
    "        self.initial = nn.Conv1d(in_channels, down_channels[0], kernel_size=3, padding=1)\n",
    "        # Downsample\n",
    "        self.downs = nn.ModuleList([Block(down_channels[i], down_channels[i+1], time_embedding_dims) for i in range(len(down_channels)-1)])\n",
    "        # Upsample\n",
    "        self.ups = nn.ModuleList([Block(up_channels[i], up_channels[i+1], time_embedding_dims, downsample=False) for i in range(len(up_channels)-1)])\n",
    "        # Final layer\n",
    "        self.final = nn.Conv1d(up_channels[-1], out_channels, 1)\n",
    "    def forward(self, x, t):\n",
    "        residuals = []\n",
    "        o = self.initial(x.float())\n",
    "        #this changes the channels (1) of the 1D Input to 64 channels\n",
    "        for downsampling in self.downs:\n",
    "            o = downsampling(o, t)\n",
    "            residuals.append(o)\n",
    "            print(\"####Downsampling####\")\n",
    "        for upsampling, res in zip(self.ups, reversed(residuals)):\n",
    "            print(\"####Upsampling####\")\n",
    "            o=torch.cat((o, res), dim=1)\n",
    "            o = upsampling(o, t)\n",
    "        o = self.final(o)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NO_EPOCHS = 300\n",
    "PRINT_FREQUENCY = 10\n",
    "LR = 0.0001\n",
    "BATCH_SIZE = 128\n",
    "optimizer = torch.optim.Adam(unet.parameters(), lr=LR)\n",
    "VERBOSE= True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range (NO_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    mean_epoch_loss = []\n",
    "    #Having 128 batches of the same image\n",
    "    batch = torch.stack([torch_reshaped] * BATCH_SIZE)\n",
    "    #resulting shape is (128,1, 16384)\n",
    "    t = torch.randint(0, diffusion_model.timesteps, (BATCH_SIZE,)).long().to(device)\n",
    "    #resulting shape is (128)\n",
    "    batch_noisy_images, noise = diffusion_model.forward(batch, t, device, min_val=min_val, max_val=max_val)\n",
    "    #resulting shape is (128,1, 16384)\n",
    "    predicted_noise = unet(batch_noisy_images, t)\n",
    "    print('Data type of predicted_noise:', predicted_noise.dtype)\n",
    "    print('Data type of noise:', noise.dtype)\n",
    "    optimizer.zero_grad()\n",
    "    loss=torch.nn.functional.mse_loss(predicted_noise.float(), noise.float())\n",
    "    mean_epoch_loss.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    end_time = time.time()  # Stop measuring the epoch duration\n",
    "    epoch_duration = end_time - start_time\n",
    "    print(f\"Epoch: {epoch} | Train Loss {np.mean(mean_epoch_loss)} | Duration {epoch_duration//60:.0f}m {epoch_duration%60:.0f}s\")\n",
    "    if epoch % PRINT_FREQUENCY == 0:\n",
    "        print('---')\n",
    "        print(f\"Epoch: {epoch} | Train Loss {np.mean(mean_epoch_loss)}\")\n",
    "        if VERBOSE:\n",
    "            with torch.no_grad():\n",
    "                plot_noise_distribution(noise, predicted_noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save unet\n",
    "torch.save(unet, 'unet_Conv1d_HS8EC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load unet\n",
    "unet = torch.load('unet_Conv1d_HS8EC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    imgs = []\n",
    "    raw_list = []\n",
    "    img = torch.randn(1, 1, 16384).to(device)\n",
    "    for i in reversed(range(diffusion_model.timesteps)):\n",
    "        t = torch.full((1,), i, dtype=torch.long, device=device)\n",
    "        img = diffusion_model.backward(img, t, unet.eval())\n",
    "        print(img.shape)\n",
    "        print(img[0].shape)\n",
    "        if i % 50 == 0:\n",
    "            imgs.append(img[0])\n",
    "            raw_array=h.reverse_transform_array(img[0], min_val, max_val,changed_shape=True)\n",
    "            raw=f.array_to_edf(raw_array,ch_names,'eeg','test.edf')\n",
    "            raw_list.append(raw)\n",
    "            raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(imgs[5] - raw.get_data()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_list[-1].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_psd(raw_list):\n",
    "    for raw in raw_list:\n",
    "        try:\n",
    "            spectrum = raw.compute_psd()\n",
    "        except :\n",
    "            print('ok')\n",
    "        spectrum.plot(average=True, picks=\"data\", exclude=\"bads\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_psd(raw_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_psd([raw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save raw as fif\n",
    "raw_list[-1].save('overfitted_conv1d.fif', overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
