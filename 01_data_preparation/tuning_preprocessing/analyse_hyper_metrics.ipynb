{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import training as t\n",
    "import functionss  as f\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load csv in pandas dataframe\n",
    "df = pd.read_csv('hyper_metric.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get 5 highest accuracies \n",
    "df = df.sort_values(by=['Accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['Precision'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['AUC'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate f1 score from Recall and Precision\n",
    "df['F1'] = 2 * (df['Precision'] * df['Recall']) / (df['Precision'] + df['Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=['F1'], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model and print AUC\n",
    "model = keras.models.load_model('/home/ubuntu/02_hyper/ref_model')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_label=[]\n",
    "data_dir = 'data/MDD_EC'\n",
    "group_label, data_MDD = t.load_data(dataDir=data_dir,group_label=group_label, sliding_window_size=16, sliding_window_overlap=0.8)\n",
    "\n",
    "#Load and preprocess the data for Healthy\n",
    "data_dir = 'data/H_EC'\n",
    "group_label, data_H = t.load_data(dataDir=data_dir,group_label=group_label, sliding_window_size=16, sliding_window_overlap=0.8)\n",
    "\n",
    "#Trim the shape of the data if necessary\n",
    "#data_H, data_MDD= t.control_for_shape(data_H, data_MDD)\n",
    "\n",
    "#make X and y data\n",
    "X_data,y_data=t.makeX_Y_data(data_H, data_MDD)\n",
    "\n",
    "#Permutate and shuffel data\n",
    "X_data, y_data, group_label = t.permutate(X_data, y_data, group_label,4)\n",
    "\n",
    "#Split data into train and test\n",
    "X_train, X_test, y_train, y_test, groups_train, groups_test = t.split_data(X_data, y_data, group_label, [5,6,7,8,37,48,39,40])\n",
    "\n",
    "#Stratified Group K Fold\n",
    "#groups_train, groups_val, groups_test, X_train, X_val, X_test, y_train, y_val, y_test = t.stratified_group_k_fold(X_data, y_data, group_label)\n",
    "\n",
    "#expand variables\n",
    "expanded_X, expanded_y = t.expand_dim([X_train, X_test], [y_train, y_test])\n",
    "X_train, X_test = expanded_X\n",
    "y_train, y_test = expanded_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "y_pred_keras = model.predict(X_test).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test, y_pred_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change color of line to green\n",
    "plt.plot(fpr_keras, tpr_keras, label='Keras (area = {:.3f})'.format(auc_keras), color='black')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.plot([0, 1], [0, 1], 'k--', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\n",
    "# Plot the accuracy curve\n",
    "y_pred_binary = (y_pred_keras >= 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "plt.plot([0, 1], [0.5, 0.5], color='gray', linestyle='-.')\n",
    "plt.scatter(1.0, accuracy, color='r', label='Accuracy ({:.2f})'.format(accuracy))\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
