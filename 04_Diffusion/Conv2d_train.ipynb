{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import urllib\n",
    "import numpy as np\n",
    "import PIL\n",
    "import mne\n",
    "import helper as h\n",
    "import functionss as f\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_z_normalisation(X_normalized, std_X,mean_X):\n",
    "    X = (X_normalized * std_X) + mean_X \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_names=['Fp1', 'F3', 'C3', 'P3', 'O1', 'F7', 'Fz', 'Fp2', 'F4', 'C4', 'P4', 'O2', 'F8', 'T6', 'Cz', 'Pz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_array(dataDir, group_label):\n",
    "    data = []\n",
    "    # iterate trough the files in the directory and load the data\n",
    "    for i, filename in enumerate(os.scandir(dataDir)):\n",
    "        if filename.name.endswith('.npy'):\n",
    "            data_array = np.load(filename)\n",
    "            if group_label == []:\n",
    "                group_label.extend([i] * len(data_array))\n",
    "            else:\n",
    "                count = np.max(group_label)\n",
    "                group_label.extend([count + 1] * len(data_array))\n",
    "            data.append(data_array)\n",
    "    return group_label, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_label, data = load_data_from_array('/home/ubuntu/Diffusion/own_diffusion/arrays_16/selected', [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.concatenate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_norm, mean, std = f.ft_z_normalize(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.array_to_edf(x_data_norm[0], ch_names, 'eeg', 'test.edf').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.array_to_edf(reverse_z_normalisation( x_data_norm[0],std, mean), ch_names, 'eeg', 'test.edf').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_norm = np.expand_dims(x_data_norm, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_image ,x_min, x_max = h.transform_array(x_data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel:\n",
    "\tdef __init__(self, start_shedule=0.0001, end_schedule=0.02, timesteps=300, beta = 2):\n",
    "\t\tself.start_schedule = start_shedule\n",
    "\t\tself.end_schedule = end_schedule\n",
    "\t\tself.timesteps = timesteps\n",
    "\t\tself.beta = beta\n",
    "\t\t\n",
    "\t\tself.betas = torch.linspace(self.start_schedule, self.end_schedule, self.timesteps)\n",
    "\t\tself.alphas = 1-self.betas\n",
    "\t\tself.alpha_cumprod = torch.cumprod(self.alphas,axis=0)\n",
    "\n",
    "\tdef forward(self, x0, t, device):\n",
    "\t\tnoise = torch.randn_like(x0)/self.beta\n",
    "\t\tsqrt_alphas_cumprod_t = self.get_index_from_list(self.alpha_cumprod.sqrt(), t, x0.shape)\n",
    "\t\tsqrt_one_minus_alphas_cumprod_t = self.get_index_from_list(torch.sqrt(1. - self.alpha_cumprod), t, x0.shape)\n",
    "\t\tmean = sqrt_alphas_cumprod_t.to(device) * x0.to(device)\n",
    "\t\tvariance = sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device)\n",
    "\t\treturn mean + variance, noise.to(device)\n",
    "\t\n",
    "\tdef backward(self, x, t, model, **kwargs):\n",
    "\t\t\"\"\"\n",
    "\t\tCalls the model to predict the noise in the image and returns \n",
    "\t\tthe denoised image. \n",
    "\t\tApplies noise to this image, if we are not in the last step yet.\n",
    "\t\t\"\"\"\n",
    "\t\tbetas_t = self.get_index_from_list(self.betas, t, x.shape)\n",
    "\t\tsqrt_one_minus_alphas_cumprod_t = self.get_index_from_list(torch.sqrt(1. - self.alpha_cumprod), t, x.shape)\n",
    "\t\tsqrt_recip_alphas_t = self.get_index_from_list(torch.sqrt(1.0 / self.alphas), t, x.shape)\n",
    "\t\tmean = sqrt_recip_alphas_t * (x - betas_t * model(x, t, **kwargs) / sqrt_one_minus_alphas_cumprod_t)\n",
    "\t\tposterior_variance_t = betas_t\n",
    "\n",
    "\t\tif t == 0:\n",
    "\t\t\treturn mean\n",
    "\t\telse:\n",
    "\t\t\tnoise = torch.randn_like(x)\n",
    "\t\t\tvariance = torch.sqrt(posterior_variance_t) * noise \n",
    "\t\t\treturn mean + variance\n",
    "\n",
    "\t\n",
    "\t@staticmethod\n",
    "\tdef get_index_from_list(values, t, x_shape):\n",
    "\t\tbatch_size = x_shape[0]\n",
    "\t\tresult = values.gather(-1,t.cpu())\n",
    "\n",
    "\t\treturn result.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion_model = DiffusionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionEmbeddings(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, time):\n",
    "        device = time.device\n",
    "        half_dim = self.dim // 2\n",
    "        embeddings = math.log(10000) / (half_dim - 1)\n",
    "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
    "        embeddings = time[:, None] * embeddings[None, :]\n",
    "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
    "        return embeddings\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out, time_embedding_dims, labels, num_filters = 3, downsample=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.time_embedding_dims = time_embedding_dims\n",
    "        self.time_embedding = SinusoidalPositionEmbeddings(time_embedding_dims)\n",
    "        self.labels = labels\n",
    "        if labels:\n",
    "            self.label_mlp = nn.Linear(1, channels_out)\n",
    "        \n",
    "        self.downsample = downsample\n",
    "        \n",
    "        if downsample:\n",
    "            self.conv1 = nn.Conv2d(channels_in, channels_out, num_filters, padding=1)\n",
    "            self.final = nn.Conv2d(channels_out, channels_out, 4, 2, 1)\n",
    "        else:\n",
    "            self.conv1 = nn.Conv2d(2 * channels_in, channels_out, num_filters, padding=1)\n",
    "            self.final = nn.ConvTranspose2d(channels_out, channels_out, 4, 2, 1)\n",
    "            \n",
    "        self.bnorm1 = nn.BatchNorm2d(channels_out)\n",
    "        self.bnorm2 = nn.BatchNorm2d(channels_out)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(channels_out, channels_out, 3, padding=1)\n",
    "        self.time_mlp = nn.Linear(time_embedding_dims, channels_out)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, t, **kwargs):\n",
    "        o = self.bnorm1(self.relu(self.conv1(x)))\n",
    "        o_time = self.relu(self.time_mlp(self.time_embedding(t)))\n",
    "        o = o + o_time[(..., ) + (None, ) * 2]\n",
    "        if self.labels:\n",
    "            label = kwargs.get('labels')\n",
    "            o_label = self.relu(self.label_mlp(label))\n",
    "            o = o + o_label[(..., ) + (None, ) * 2]\n",
    "            \n",
    "        o = self.bnorm2(self.relu(self.conv2(o)))\n",
    "\n",
    "        return self.final(o)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, img_channels = 1, time_embedding_dims = 128, labels = False, sequence_channels = (64, 128, 256, 512, 1024)):\n",
    "        super().__init__()\n",
    "        self.time_embedding_dims = time_embedding_dims\n",
    "        sequence_channels_rev = reversed(sequence_channels)\n",
    "        \n",
    "        self.downsampling = nn.ModuleList([Block(channels_in, channels_out, time_embedding_dims, labels) for channels_in, channels_out in zip(sequence_channels, sequence_channels[1:])])\n",
    "        self.upsampling = nn.ModuleList([Block(channels_in, channels_out, time_embedding_dims, labels,downsample=False) for channels_in, channels_out in zip(sequence_channels[::-1], sequence_channels[::-1][1:])])\n",
    "        self.conv1 = nn.Conv2d(img_channels, sequence_channels[0], 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(sequence_channels[0], img_channels, 1)\n",
    "\n",
    "    \n",
    "    def forward(self, x, t, **kwargs):\n",
    "        residuals = []\n",
    "        o = self.conv1(x.float())\n",
    "        for ds in self.downsampling:\n",
    "            o = ds(o, t, **kwargs)\n",
    "            residuals.append(o)\n",
    "        for us, res in zip(self.upsampling, reversed(residuals)):\n",
    "            o = us(torch.cat((o, res), dim=1), t, **kwargs)\n",
    "            \n",
    "        return self.conv2(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet(labels=False)\n",
    "unet.to(device)\n",
    "\n",
    "NO_EPOCHS = 500\n",
    "PRINT_FREQUENCY = 40\n",
    "LR = 0.0001\n",
    "BATCH_SIZE = 128\n",
    "optimizer = torch.optim.Adam(unet.parameters(), lr=LR)\n",
    "VERBOSE= True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_noise_distribution(noise, predicted_noise):\n",
    "    plt.hist(noise.cpu().numpy().flatten(), density = True, alpha = 0.8, label = \"ground truth noise\")\n",
    "    plt.hist(predicted_noise.cpu().numpy().flatten(), density = True, alpha = 0.8, label = \"predicted noise\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_image.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all mins and max values of all the arraysin the array of (150,1,16,1024) for the arrays in the 3rd dimenstion and than take the mean\n",
    "\n",
    "mins = []\n",
    "maxs = []\n",
    "for i in range(0,x_data_norm.shape[0]):\n",
    "    mins.append(np.min(x_data_norm[i][0][0]))\n",
    "    maxs.append(np.max(x_data_norm[i][0][0]))\n",
    "x_min_av = np.mean(mins)\n",
    "x_max_av= np.mean(maxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get global min and max from tensor (150,1,16,1024)\n",
    "\n",
    "x_min_global = np.min(x_data_norm)\n",
    "x_max_global = np.max(x_data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_min_global, x_max_global)\n",
    "print(x_min, x_max)\n",
    "print(x_min_av, x_max_av)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anders nromeiren\n",
    "#tensor = h.transform_array_global(x_data, xmin, xmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "dataset = TensorDataset(torch_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=8, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "unet = UNet(labels=False)\n",
    "unet.to(device)\n",
    "\n",
    "NO_EPOCHS = 500\n",
    "PRINT_FREQUENCY = 40\n",
    "LR = 0.0001\n",
    "BATCH_SIZE = 128\n",
    "optimizer = torch.optim.Adam(unet.parameters(), lr=LR)\n",
    "VERBOSE= True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(250):\n",
    "    mean_epoch_loss = []\n",
    "    mean_epoch_loss_val = []\n",
    "    for batch in trainloader:\n",
    "        batch = batch[0]\n",
    "        print(batch.shape)\n",
    "        t = torch.randint(0, diffusion_model.timesteps, (BATCH_SIZE,)).long().to(device)\n",
    "        batch = batch.to(device)\n",
    "        batch_noisy, noise = diffusion_model.forward(batch, t, device) \n",
    "        predicted_noise = unet(batch_noisy, t)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = torch.nn.functional.mse_loss(predicted_noise.float(), noise.float()) \n",
    "        mean_epoch_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % PRINT_FREQUENCY == 0:\n",
    "        print('---')\n",
    "        print(f\"Epoch: {epoch} | Train Loss {np.mean(mean_epoch_loss)}\")\n",
    "        if VERBOSE:\n",
    "            with torch.no_grad():\n",
    "                plot_noise_distribution(noise, predicted_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save unet\n",
    "torch.save(unet, 'unet_conv2d_with_15_samples_znorm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load unet\n",
    "\n",
    "unet = torch.load('unet_conv2d_with_13samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_names=['Fp1', 'F3', 'C3', 'P3', 'O1', 'F7', 'Fz', 'Fp2', 'F4', 'C4', 'P4', 'O2', 'F8', 'T6', 'Cz', 'Pz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DISPLAY_IMAGES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_tensor = torch.empty((NUM_DISPLAY_IMAGES, 1, 16, 1024)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(NUM_DISPLAY_IMAGES):\n",
    "        img = torch.randn(1, 1, 16, 1024).to(device)\n",
    "        for j in reversed(range(diffusion_model.timesteps)):\n",
    "            t = torch.full((1,), j, dtype=torch.long, device=device)\n",
    "            img = diffusion_model.backward(x=img, t=t, model=unet.eval().to(device))\n",
    "            imgs_tensor[i] = img[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imgs_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_z_normalisation(X_normalized, std_X,mean_X):\n",
    "    X = (X_normalized * std_X) + mean_X \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = imgs_tensor[0].view(16,1024)\n",
    "array = reverse_z_normalisation(array, std, mean)\n",
    "raw = f.array_to_edf(array.cpu().numpy(), ch_names, 'eeg', 'test_eeg',sfreq=256)\n",
    "raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = imgs_tensor[0].view(16, 1024)\n",
    "array = reverse_z_normalisation(array, std, mean)\n",
    "raw_global = h.reverse_transform_array(array, x_min_global, x_max_global)\n",
    "raw_global=f.array_to_edf(raw_global,ch_names,'eeg','test.edf')\n",
    "raw_local = h.reverse_transform_array(array,x_min, x_max)\n",
    "raw_local=f.array_to_edf(raw_local,ch_names,'eeg','test.edf')\n",
    "raw_av = h.reverse_transform_array(array, x_min_av, x_max_av)\n",
    "raw_av=f.array_to_edf(raw_av,ch_names,'eeg','test.edf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the raws \n",
    "raw_global.plot()\n",
    "plt.show()\n",
    "raw_local.plot()\n",
    "plt.show()\n",
    "raw_av.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_list_global_min_max = []\n",
    "for idx, img in enumerate(imgs_tensor):\n",
    "    array = img.view(16, 1024)\n",
    "    #array = reverse_z_normalisation(array, std, mean) \n",
    "    raw_array=h.reverse_transform_array(array, x_min, x_max,changed_shape=False)\n",
    "    raw=f.array_to_edf(raw_array,ch_names,'eeg','test.edf')\n",
    "    raw_list_global_min_max.append(raw)\n",
    "    raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_list_av_min_max = []\n",
    "for idx, img in enumerate(imgs_tensor):\n",
    "    array = img.view(16, 1024)\n",
    "    raw_array=h.reverse_transform_array(array, x_min_av, x_max_av,changed_shape=False)\n",
    "    raw=f.array_to_edf(raw_array,ch_names,'eeg','test.edf')\n",
    "    raw_list_av_min_max.append(raw)\n",
    "    raw.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_psd(raw_list):\n",
    "    for raw in raw_list:\n",
    "        try:\n",
    "            spectrum = raw.compute_psd()\n",
    "        except :\n",
    "            print('ok')\n",
    "        spectrum.plot(average=True, picks=\"data\", exclude=\"bads\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_psd(raw_list_global_min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_psd(raw_list_av_min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_from_source = f.array_to_edf(x_data[5], ch_names, 'eeg', 'test_eeg',sfreq=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_psd([raw_from_source])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
